{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 16), dtype=float32, numpy=\n",
       "array([[ 0.03793888,  0.03837431,  0.07881299, -0.01210025, -0.23910588,\n",
       "         0.069548  , -0.17152178, -0.3544281 ,  0.11446775,  0.05249958,\n",
       "        -0.15397947,  0.06283358,  0.09527606, -0.03975724, -0.33828694,\n",
       "         0.16966903],\n",
       "       [ 0.04954688,  0.03473268,  0.01283243,  0.18453446, -0.24783552,\n",
       "         0.20232323, -0.2460535 , -0.39256862,  0.36996096,  0.08043034,\n",
       "        -0.09084583, -0.00157549,  0.17253639, -0.12066321, -0.0892628 ,\n",
       "         0.1797708 ]], dtype=float32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = tf.keras.models.Sequential([tf.keras.layers.Dense(256,activation = tf.nn.relu),\n",
    "                                  tf.keras.layers.Dense(16),\n",
    "                                 ])\n",
    "\n",
    "X = tf.random.uniform((2,20))\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = tf.keras.layers.Dense(256,activation=tf.nn.relu)\n",
    "        self.out = tf.keras.layers.Dense(10)\n",
    "    \n",
    "    def call(self,X):\n",
    "        return self.out(self.hidden((X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 20), dtype=float32, numpy=\n",
       "array([[0.5648432 , 0.5074893 , 0.83366716, 0.86529446, 0.36031997,\n",
       "        0.5900333 , 0.4224981 , 0.32877505, 0.809008  , 0.32848155,\n",
       "        0.7628732 , 0.29490972, 0.468346  , 0.3231895 , 0.09616756,\n",
       "        0.99117815, 0.53065145, 0.24529135, 0.6122583 , 0.34063423],\n",
       "       [0.5407821 , 0.00309324, 0.6825639 , 0.6181811 , 0.2304883 ,\n",
       "        0.24587512, 0.78691196, 0.92343867, 0.23041868, 0.3842492 ,\n",
       "        0.6716305 , 0.48350096, 0.09825265, 0.1650809 , 0.18695128,\n",
       "        0.1655811 , 0.33515513, 0.84262824, 0.18564045, 0.45268   ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = MLP()\n",
    "net(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySeq(tf.keras.Model):\n",
    "    def __init__(self,*args):\n",
    "        super().__init__()\n",
    "        self.modules = []\n",
    "        for block in args:\n",
    "            self.modules.append(block)\n",
    "        \n",
    "    \n",
    "    def call(self,X):\n",
    "        for module in self.modules:\n",
    "            X = module(X)\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 10), dtype=float32, numpy=\n",
       "array([[-0.5202818 ,  0.4089492 , -0.1552027 , -0.02211266, -0.20047441,\n",
       "         0.02488761, -0.3818569 , -0.26887792, -0.27240628,  0.13486868],\n",
       "       [-0.25035575,  0.32752466, -0.16890489,  0.06006361, -0.31214896,\n",
       "        -0.02258125, -0.21423237, -0.21915725, -0.18722586,  0.08279666]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = MySeq(\n",
    "    tf.keras.layers.Dense(units=256, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10))\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixedHiddenMLP(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.rand_weight = tf.constant(tf.random.uniform((20,20)))\n",
    "        self.dense = tf.keras.layers.Dense(20,activation = tf.nn.relu)\n",
    "    \n",
    "    def call(self,inputs):\n",
    "        X = self.flatten(inputs)\n",
    "        X = tf.nn.relu(tf.matmul(X,self.rand_weight)+1)\n",
    "        X = self.dense(X)\n",
    "        \n",
    "        while tf.reduce_sum(tf.math.abs(X))>1:\n",
    "            X/=2\n",
    "        \n",
    "        return tf.reduce_sum(X)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.7846392>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = FixedHiddenMLP()\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.7488892>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NestMLP(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = tf.keras.Sequential()\n",
    "        self.net.add(tf.keras.layers.Dense(64,activation=tf.nn.sigmoid))\n",
    "        self.net.add(tf.keras.layers.Dense(32,activation=tf.nn.sigmoid))\n",
    "        self.dense = tf.keras.layers.Dense(8)\n",
    "    \n",
    "    def call(self,inputs):\n",
    "        return self.dense(self.net(inputs))\n",
    "\n",
    "chimera = tf.keras.Sequential()\n",
    "chimera.add(NestMLP())\n",
    "chimera.add(tf.keras.layers.Dense(20,activation=tf.nn.relu))\n",
    "chimera.add(FixedHiddenMLP())\n",
    "chimera(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParallelNet(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net1 =tf.keras.Sequential()\n",
    "        self.net1.add(tf.keras.layers.Dense(64,activation=tf.nn.relu))\n",
    "        self.net1.add(tf.keras.layers.Dense(32,activation=tf.nn.relu))\n",
    "        self.net2 =tf.keras.Sequential()\n",
    "        self.net2.add(tf.keras.layers.Dense(32,activation=tf.nn.relu))\n",
    "        self.net2.add(tf.keras.layers.Dense(16,activation=tf.nn.relu))\n",
    "    \n",
    "    def call(self,inputs):\n",
    "        return tf.concat([self.net1(inputs),self.net2(inputs)],axis=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 48), dtype=float32, numpy=\n",
       "array([[0.        , 0.        , 0.        , 0.01999505, 0.        ,\n",
       "        0.        , 0.25348017, 0.45639056, 0.3420291 , 0.04271244,\n",
       "        0.7868906 , 0.02009377, 0.16264716, 0.        , 0.        ,\n",
       "        0.        , 0.17544225, 0.        , 0.28852427, 0.05138777,\n",
       "        0.        , 0.37894076, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.1694813 , 0.02351716,\n",
       "        0.33409226, 0.        , 0.        , 0.0605364 , 0.        ,\n",
       "        0.        , 0.        , 0.6479514 , 0.47136533, 0.        ,\n",
       "        0.38354614, 0.        , 0.0941817 , 0.        , 0.        ,\n",
       "        0.0858431 , 0.33914393, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.18149623, 0.16832739,\n",
       "        0.        , 0.        , 0.16856319, 0.09710114, 0.08903161,\n",
       "        0.44052768, 0.1532836 , 0.01553615, 0.        , 0.        ,\n",
       "        0.        , 0.08770853, 0.1512183 , 0.15587816, 0.        ,\n",
       "        0.        , 0.11011308, 0.05870064, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.00824715, 0.11669379, 0.        ,\n",
       "        0.36967278, 0.        , 0.07849132, 0.477695  , 0.07639103,\n",
       "        0.        , 0.28385752, 0.218083  , 0.34436518, 0.        ,\n",
       "        0.6290498 , 0.        , 0.        , 0.        , 0.00684604,\n",
       "        0.        , 0.5107051 , 0.        ]], dtype=float32)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = ParallelNet()\n",
    "test(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
